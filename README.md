# transformer-encoder

Схема энкодера архитектуры Трансформер. Основная идея визуализации - уместить на одной диаграмме весь энкодер Трансформера, сохранив при этом все важные детали. Сделана в draw.io, [ссылка](https://drive.google.com/file/d/1D21djqdpxG8tia3Zig9O_FsiL65IT89S/view?usp=sharing) для создания копий и редактирования.


Визуализация основана на материалах лекций курса [Stanford CS224N NLP with Deep Learning](https://youtu.be/LWMzyfvuehA?si=JXTS_xrP1rU7QNOK), [блога](http://jalammar.github.io/illustrated-transformer/) Jay Alammar, а также [видео-туториала](https://youtu.be/kCc8FmEb1nY?si=fSZvQs9DXcFO6AoU) и реализации модели [nanoGPT](https://github.com/karpathy/nanoGPT) Andrej Karpathy.

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Transformer encoder visualisation. The main purpose of the visualisation is to fit the whole Transformer encoder block into one diagram while not omitting any important details. Made with draw.io, [link](https://drive.google.com/file/d/1D21djqdpxG8tia3Zig9O_FsiL65IT89S/view?usp=sharing) for copying and editing.

This visualisation is based on lectures [Stanford CS224N NLP with Deep Learning](https://youtu.be/LWMzyfvuehA?si=JXTS_xrP1rU7QNOK), [blogpost](http://jalammar.github.io/illustrated-transformer/) by Jay Alammar, as well as [tutorial video](https://youtu.be/kCc8FmEb1nY?si=fSZvQs9DXcFO6AoU) and [nanoGPT](https://github.com/karpathy/nanoGPT) model implementation by Andrej Karpathy.
