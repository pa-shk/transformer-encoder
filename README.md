# transformer-encoder

Схема энкодера архитектуры Трансформер. Основная идея визуализации - уместить на одной диаграмме весь энкодер Трансформера, сохранив при этом все важные детали. 


Визуализация основана на материалах лекций курса [Stanford CS224N NLP with Deep Learning](https://youtu.be/LWMzyfvuehA?si=JXTS_xrP1rU7QNOK), а также [видео-туториала](https://youtu.be/kCc8FmEb1nY?si=fSZvQs9DXcFO6AoU) и реализации модели [nanoGPT](https://github.com/karpathy/nanoGPT) Андрея Карпатого.

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Transformer encoder visualisation. The main purpose of the visualisation is to fit the whole Transformer encoder block into one diagram while not omitting any important details. 

This visualisation is based on lectures [Stanford CS224N NLP with Deep Learning](https://youtu.be/LWMzyfvuehA?si=JXTS_xrP1rU7QNOK), as well as [tutorial video](https://youtu.be/kCc8FmEb1nY?si=fSZvQs9DXcFO6AoU) and [nanoGPT](https://github.com/karpathy/nanoGPT) model implementation by Andrej Karpathy.
